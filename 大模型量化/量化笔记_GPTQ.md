# 大模型量化与混合精度详解

## 1.1 核心概念辨析

为了厘清容易混淆的概念，我们需要区分“混合精度训练”与“大模型量化”的应用场景与目的。

| 概念                          | 场景      | 数据格式    | 核心目的                                                     |
| :---------------------------- | :-------- | :---------- | :----------------------------------------------------------- |
| **混合精度训练 (AMP)**        | 训练/微调 | FP16 + FP32 | 在保持精度的前提下，减少显存占用，加速**训练**过程。         |
| **大模型量化 (Quantization)** | 推理/部署 | INT8 / INT4 | 降低参数精度，大幅减少显存占用，提高**推理**速度，使其能在消费级硬件上运行。 |

> **注**：量化通常指的是将高精度浮点数（FP16/FP32）映射为低精度整数（INT8/INT4）。

---

## 1.2 量化技术流派

量化技术主要分为两大流派，目前普通用户和开发者接触最多的是 PTQ。

### 1. PTQ (Post-Training Quantization, 训练后量化)
*   **定义**：模型训练完成后，直接对权重/激活值进行压缩。
*   **特点**：无需重新训练，计算资源消耗低。
*   **代表技术**：**GPTQ**, **AWQ**, **GGUF**, **LLM.int8()**。

### 2. QAT (Quantization-Aware Training, 量化感知训练)
*   **定义**：在训练过程中模拟量化操作，让模型在训练时就“适应”低精度带来的误差。
*   **特点**：精度损失最小，但训练难度大、成本极高。

---

## 1.3 量化的数学原理

量化的本质是建立浮点数（$r$）与整数（$q$）之间的映射关系。

### 1. 对称量化 (Symmetric Quantization)
通常用于 **AbsMax 量化**。这种方法计算简单，但对非对称分布的数据（如 ReLU 激活后的数据）可能造成范围浪费。

*   **步骤 1：寻找绝对值最大值**
    $$ \text{absmax} = \max(|X|) $$
*   **步骤 2：计算缩放因子 (Scale)**
    由于 INT8 的表示范围为 $[-127, 127]$：
    $$ S = \frac{\text{absmax}}{127} $$
*   **步骤 3：量化映射**
    $$ X_{\text{int8}} = \text{round}\left( \text{clamp}\left( \frac{X_{\text{fp32}}}{S}, -127, 127 \right) \right) $$
*   **步骤 4：反量化 (Dequantization)**
    $$ X_{\text{fp32}} \approx X_{\text{int8}} \times S $$

### 2. 非对称量化 (Asymmetric / Zeropoint Quantization)
通过引入零点（Zero-point），解决数据分布不对称的问题（即数据的 0 点并不对应整数的 0 点）。

假设浮点数范围为 $[r_{\min}, r_{\max}]$，目标整数范围为 $[q_{\min}, q_{\max}]$。映射公式为线性变换：
$$ q = \text{round}\left( \frac{r}{S} + Z \right) $$

*   **(1) 缩放系数 (Scale):**
    $$ S = \frac{r_{\max} - r_{\min}}{q_{\max} - q_{\min}} $$
*   **(2) 零点 (Zero-point):**
    $$ Z = \text{round}\left( q_{\min} - \frac{r_{\min}}{S} \right) $$
*   **(3) 反量化过程:**
    $$ r \approx S \times (q - Z) $$

### 3. 百分位数量化（都是基于上述原理）

为了减轻上述两种算法对离群值的敏感性，在校准期间收集数值的分布，然后确定上下限的百分数阈值，比如 0.1% 和 99.9%，那么在这个范围外的数都会变为最大值或最小值。

**优点：**

- 比 MinMax 对异常值更具抵抗力。
- 实现相对简单，只需收集直方图和计算百分位数。

**缺点：**

- 对被截断的异常值引入饱和误差。如果这些异常值带有重要信息，截断它们可能会对精度产生负面影响。
- 需要选择合适的百分位数，这成为一个需要调整的超参数。最佳百分位数可能因不同层或模型而异。



### 4. 熵（KL散度）量化

采用更科学的方式选择这个截断范围，**KL 散度：**平衡两个分布（$P$ 和 $Q$）之间差异度。希望让截断后量化的数据分布和原始的数据分布最像。

**具体步骤：**
1.  **准备**：统计原始数据分布 $P$（FP32）。
2.  **遍历测试**：假设我们尝试很多个不同的截断阈值（比如 $T=1, T=2, ..., T=100$）。
3.  **模拟量化**：对于每一个 $T$：
    *   把数据截断到 $[-T, T]$ 并量化。
    *   然后再反量化回来，得到分布 $Q$。
4.  **对比**：计算 $P$ 和 $Q$ 之间的 KL 散度。
5.  **决策**：找到那个**KL 散度最小**的 $T$，这就是最佳截断阈值。



*   **优点**：
    *   **抗干扰**
    *   **精度高**：因为范围变小了（比如从 $[-1, 1000]$ 变成了 $[-5, 5]$），每一格（Step）代表的数值更精细了，主要数据被照顾得更好。
*   **缺点**：
    *   **信息丢失**：被切掉的那 $0.1\%$ 数据如果包含重要信息（比如某些特殊的激活信号），模型可能会变傻。
    *   **调参麻烦**：选 $99.9\%$ 还是 $99\%$？不同模型、不同层可能不一样，需要试。

## 2. 算法选择指南

根据数据的**分布特征**来决定：

| 目标对象                 | 数据特征                                   | 推荐算法                        | 原因                                                         |
| :----------------------- | :----------------------------------------- | :------------------------------ | :----------------------------------------------------------- |
| **权重 (Weights)**       | **稳定、对称**(通常像正态分布)             | **MinMax** 或 **百分位数**      | 权重是训练好的，通常没有极端离群值，且分布比较“漂亮”，简单方法就够用。 |
| **激活值 (Activations)** | **不稳定、非对称、长尾**(可能有巨大离群值) | **熵量化 (KL)** 或 **百分位数** | 激活值随输入变化，且经常有怪异的极值（如 ReLU 后的长尾）。MinMax 会导致精度崩塌，必须用截断策略。 |

### 总结对比表

| 算法         | 核心逻辑             | 速度 | 对离群值抵抗力  | 精度上限        |
| :----------- | :------------------- | :--- | :-------------- | :-------------- |
| **MinMax**   | 以此为界，全都要     | 最快 | 极差 (被带跑偏) | 低 (易受干扰)   |
| **百分位数** | 切掉头尾，保留中间   | 中等 | 强 (强制切除)   | 中高 (依赖调参) |
| **熵 (KL)**  | 算出来的“最像”截断点 | 最慢 | 强 (智能平衡)   | **最高**        |

---

## 3. LLM.int8() 技术详解

**LLM.int8()** 本质上属于 **PTQ（在线动态量化）**。它的核心贡献在于解决了大模型中“离群值”导致量化精度崩塌的问题。

### 核心思想：混合精度分解 (Mixed Precision Decomposition)
大模型中绝大部分数值分布集中，适合量化；但极少数特征维度存在数值巨大的**系统性离群值 (Outliers)**。如果强行统一量化，这些离群值会拉大 Range，导致正常值的量化分辨率极低。

**解决方案**：根据阈值 $\alpha$ 将矩阵分解为两部分，分别计算。

1. **分解矩阵**：
   $$ X = X_{\text{regular}} + X_{\text{outlier}} $$
   $$ W = W_{\text{regular}} + W_{\text{outlier}} $$
   > 注：这里 $X_{\text{outlier}}$ 仅保留超过阈值的列，其余位置补 0；$X_{\text{regular}}$ 则保留其余部分。

2. **分流计算**：
   *   **离群部分 ($X_{\text{outlier}}$)**：保持 **FP16** 高精度计算，确保不损失精度。
   *   **正常部分 ($X_{\text{regular}}$)**：转换为 **INT8** 进行向量化计算，提高效率。

3. **合并结果**：
   由于分解是基于维度的（类似于掩码操作），交叉项乘积为 0，因此：
   $$ \text{Result} \approx (X_{\text{regular}} \times W_{\text{regular}})_{\text{INT8}} + (X_{\text{outlier}} \times W_{\text{outlier}})_{\text{FP16}} $$





## 4. 补充：LLM.int8() 的具体动态量化与推理流程

LLM.int8() 的核心魔法在于**推理时（Inference-time）**的动态处理。它不仅仅是将模型存为 8-bit，更关键的是在计算矩阵乘法（$Y = X \times W$）时，如何实时处理数据。

### 1. 前置概念：逐向量量化 (Vector-wise Quantization)
传统的量化可能整个矩阵共用一个缩放因子 $S$（Per-tensor），这会导致精度损失。LLM.int8() 采用更精细的策略：
*   **对于权重 $W$**：每一**列**都有独立的缩放常数。
*   **对于输入（激活值）$X$**：每一**行**（即每个 Token）都有独立的缩放常数。
这保证了量化的精度基础。

### 2. 详细推理流程 (Step-by-Step)

假设我们正在进行一层 Transformer 的计算，输入是隐藏层状态 $X$（FP16），权重是 $W$（已存储为 INT8）。

#### 第一步：离群值检测 (Outlier Detection)
当输入数据 $X$（FP16）到来时，系统会扫描 $X$ 的每一个元素。
*   **规则**：检查每一列（特征维度）中是否存在绝对值超过阈值（通常为 **6.0**）的元素。
*   **结果**：找到那些包含“剧烈波动”数值的特征列索引，记为 $I_{\text{outlier}}$。
    > **为什么叫动态？** 因为 $X$ 是用户输入产生的，每一轮对话的 $X$ 都不一样，所以离群值的列也是实时变化的。

#### 第二步：混合精度分解 (Decomposition)
根据上一步找到的索引 $I_{\text{outlier}}$，将矩阵 $X$ 和权重矩阵 $W$ 实时“撕”成两半：

1.  **离群部分 (FP16 通道)**：
    *   从 $X$ 中提取出这些列，形成 $X_{\text{fp16}}$。
    *   从 $W$ 中提取出对应的行（反量化为 FP16），形成 $W_{\text{fp16}}$。
    *   *注：这部分数据量极小（通常 < 0.1%），但对精度至关重要。*

2.  **正常部分 (INT8 通道)**：
    *   $X$ 中剩下的列是平稳的，将其进行 **动态量化**：
        1.  计算每一行的绝对最大值。
        2.  计算缩放因子 $S_x$。
        3.  映射为 INT8，形成 $X_{\text{int8}}$。
    *   $W$ 中剩下的行本身就是 INT8 存储的，直接取出作为 $W_{\text{int8}}$。

#### 第三步：分流计算 (Matrix Multiplication)
现在我们并行执行两次矩阵乘法：

1.  **高精度流**：
    $$ O_{\text{outlier}} = X_{\text{fp16}} \times W_{\text{fp16}} $$
    *(结果是 FP16)*

2.  **低精度流**：
    $$ O_{\text{regular}} = X_{\text{int8}} \times W_{\text{int8}} $$
    *(结果是 INT32)*
    *   **反量化**：计算完成后，立刻利用权重和输入的缩放因子 ($S_w, S_x$) 将结果转回 FP16。
    $$ O_{\text{regular\_fp16}} = O_{\text{regular}} \times S_w \times S_x $$

#### 第四步：结果合并 (Merge)
将两部分结果相加，得到最终输出：
$$ Y_{\text{output}} = O_{\text{outlier}} + O_{\text{regular\_fp16}} $$

### 3. 总结：为什么它慢但效果好？

*   **效果好**：因为它不像普通量化那样强制把 100 和 0.1 压在同一个 8-bit 空间里。它“尊重”了那 0.1% 的捣乱分子（离群值），给它们开了 VIP 通道（FP16）。
*   **速度慢**：因为每次推理都要**实时**扫描 $X$、**实时**拆分矩阵、**实时**反量化部分权重。这比直接把整个矩阵扔进 GPU 算要繁琐得多。

---

## 5. 训练后量化 (PTQ) 流程与分类

### 1. PTQ 的对象分类
*   **Weight-Only (仅权重量化)**
    *   **含义**：只压缩模型参数，激活值计算时仍用 FP16。
    *   **优缺**：精度损失极小，显存节省明显。
    *   **代表**：**GPTQ**, **AWQ**, **GGUF (k-quants)**。*(目前最主流)*
*   **Weight + Activation (全量化)**
    *   **含义**：参数和激活值都量化。
    *   **优缺**：利用 INT8 Tensor Core 速度最快，但精度极易受损，需配合 SmoothQuant 等技术处理离群值。

### 2. 标准 PTQ 实施流程
PTQ 的过程实际上就是寻找最佳 $S$ 和 $Z$ 参数并应用的过程。

1.  **准备模型**：加载预训练的全精度模型（如 FP16/FP32）。
2.  **数据校准 (Calibration)**：
    *   准备一个小型的、有代表性的数据集（校准集）。
    *   让模型在该数据集上运行推理。
3.  **统计范围 (Observer)**：
    *   收集每一层的权重和**激活值**的统计数据（主要是 $r_{\min}$ 和 $r_{\max}$）。
4.  **计算参数**（静态体现）：
    *   根据统计数据，计算最佳的 **Scale ($S$)** 和 **Zero-point ($Z$)**。（这样在推理过程中就不需要生成而是使用先验的。
    *   *注：GPTQ/AWQ 等算法在此步骤有更复杂的优化策略（如最小化重构误差）。*
5.  **实施量化**：
    *   利用 $S$ 和 $Z$ 将 FP32 权重转换为 INT8/INT4。
6.  **保存模型**：
    *   存储量化后的权重以及对应的量化参数（$S, Z$），供推理引擎在运行时进行反量化或直接计算。

### 3. 静态量化与动态量化

#### 静态量化

静态量化是在执行推理*之前*对模型权重和激活进行量化。由于激活的取值范围可能因输入数据而异，静态量化需要一个校准步骤。

**优点：**

- 更高的潜在性能：由于所有量化参数都预先固定，推理可以在支持的硬件（CPU、GPU、加速器）上完全使用高度优化的整数算术指令运行，从而实现最大程度的加速和能效。
- 更低的推理开销：计算激活范围或量化参数无需运行时成本。

**缺点：**

- 需要校准数据集。
- 对离群值敏感。

**注意这里 LLM 主流的 Weight-Only 静态量化（W4A16/W8A16）和一般的不一样：** 对输入不进行量化，对权重进行反量化。

#### 动态量化

动态量化，在某些情况下也常被称为“仅权重量化”，采取了不同的方法。权重在离线阶段量化，这一点与静态量化类似。然而，激活是在推理过程中*动态*或*即时*量化的。

1. **离线权重量化：** 模型权重被转换为低精度整数格式（例如，INT8）并存储。
2. **推理：**
   - 当输入数据到来时，激活会逐层处理。
   - **对于涉及量化权重的操作（如矩阵乘法），传入的浮点激活会在操作前立即量化**。它们的范围（最小值/最大值）是根据当前批次数据动态计算的。
   - 计算（例如，`INT8` 权重 * `INT8` 激活）得以执行。
   - 结果通常在传递给需要浮点输入的下一个操作或层（如某些激活函数或归一化层）之前，反量化回浮点数（FP32）。



------



# 量化推理中的反量化与噪声分析

## 1. 核心结论
*   **误区澄清**：反量化（Dequantization）本身**不产生噪声**。
*   **真实情况**：噪声（误差）是在**量化（FP16 $\to$ INT）**那一刻产生的（有损压缩）。反量化只是将“低精度整数”还原为“高精度浮点数”的格式转换（$r = S \times q + Z$），它只是“显露”了误差，而非“增加”误差。

## 2. 现代推理流程 (以 W4A16 为例)

现代 LLM 推理采用**“低精度存储，高精度计算”**的策略，流程如下：

1.  **加载 (Load)**：从显存读取 INT4 权重（**节省显存**）。
2.  **反量化 (Dequant)**：在计算单元（Tensor Core）附近，瞬间将 INT4 恢复为 FP16（**恢复格式**）。
3.  **计算 (Compute)**：使用 FP16 进行矩阵乘法（**高精度环境**）。
    *   $$Y_{\text{fp16}} = X_{\text{fp16}} \times \text{Dequant}(W_{\text{int4}})$$
    > **性能真相**：W4A16 的加速主要来自**显存带宽的节省**（读权重快了 4 倍），而非计算加速（因为计算核心还是在跑 FP16）。

> **关键点**：中间结果（Activations）始终保持 FP16 流动，避免了“每一层都重新量化”带来的二次噪声引入。

## 3. 为什么误差不会层层累积导致崩溃？

虽然初始量化有误差，但通过以下机制抑制了传播：

### A. 算法层面的补偿 (Calibration)
*   **技术**：GPTQ, AWQ。
*   **原理**：在量化前，通过数学方法调整未量化的参数，使得“量化后的输出”在数学期望上无限接近“原版 FP16 的输出”。误差被算法“预消化”了。

### B. 物理层面的隔离 (Outlier Protection)
*   **技术**：LLM.int8(), AWQ。
*   **原理**：对于极少数容易放大噪声的**离群值**（Outliers），**不进行量化**，直接使用 FP16 传输和计算。

### C. 计算层面的缓冲 (High Precision Compute)
*   **原理**：利用 FP16（甚至 FP32 累加器）的高精度计算环境，来消化低精度权重带来的微小扰动。



------



# GPTQ 算法详解

## 0. 优化目标

GPTQ 的本质是一个数学优化问题：如何修改权重，能使得量化前后的输出**误差最小**。这是为了解决一般的 PTQ 在权重四舍五入时精度损失问题。

目标：$$ \text{argmin}_{\hat{W}} || WX - \hat{W}X ||_2^2 $$



## 1. 前置知识：Optimal Brain Damage (OBD)

OBD：移除网络中不重要的权重，可以期望获得更好的泛化能力、减少所需的训练示例数量，以及提高学习或分类速度。

OBD 认为：**权重小不代表不重要。如果误差函数在这个权重方向上非常陡峭（二阶导数大），哪怕权重很小，删掉它也会导致 Loss 暴涨**。

实际上上述内容就是权重剪枝，希望知道哪些参数删掉后对权重影响最少。而衡量重要性就要找到一个标准，于是提出**"权衡一个权重的重要性应该看看，删掉它后，Loss 的增加"**。

于是有了下面函数，给权重一个微小的导数，简单理解就是多元函数的泰勒展开取到二阶展开，此时 $H$ 就是海森公式：
$$
\delta E \approx \underbrace{\mathbf{g}^T \delta w}_{\text{一阶项}} + \underbrace{\frac{1}{2} \delta w^T \mathbf{H} \delta w}_{\text{二阶项}}
$$
*   $\mathbf{g}^T$：梯度
*   $\mathbf{H}$：海森矩阵（Hessian Matrix）

#### 1. 三个假设：

海森矩阵并不好计算，于是有了三个假设：

- 网络已经收敛了，意味着对参数的梯度为 0，那么一阶导为 0。
- 对角化，忽略了权重之间的影响。交叉项 $\frac{\partial^2 E}{\partial w_i \partial w_j} = 0, i \neq j$，这样就进一步化简了二阶项，$\delta E \approx \frac{1}{2} \sum_k h_{kk} (\delta w_k)^2$。
- 假设 Loss 函数在局部就是一个碗状结构，意思是忽略更高阶导。

#### 2. 推导显著性公式（也就是删除某个权重后带来的影响）

操作：删除 $w_k$，意味着让它的变化量 $\delta w_k = -w_k$（也就是变成 0）。

损失变化：$$ \delta E_k \approx \frac{1}{2} h_{kk} (-w_k)^2 = \frac{1}{2} h_{kk} w_k^2 $$（基于第二个假设）

这就意味着，我们不应该删除，权重本身很大，或者权重在这点二阶导很大的权重。

#### 3. 分析

实际上从三个假设来看，这种方式对后来有启发意义，删除的权重不能仅仅看权重大小，但是它忽略了权重之间的相关性（没有逆补偿机制）。



## 2. 前置知识：Optimal Brain Surgeon (OBS)

OBS：也是最初用于**剪枝**，思考：让权重变为 0，同时让损失函数增加的最少?

OBS 相较于 OBD 有以下变动：（1）考虑二阶矩阵 $H$ 的全部（也就是相关性） （2）补偿机制，有人删，就要调整其他人来补偿。

### 1. 目标函数

$$
\delta E \approx \mathbf{g}^T \delta w + \frac{1}{2} \delta w^T \mathbf{H} \delta w 
$$

仍然假设网络收敛，去掉第一项。

### 2. 拉格朗日乘法求解

因为带有限制 $\mathbf{e}_q^T \delta w = -w_q$ ($\delta w$ 的第 $q$ 位变化为 $-w_q$):
$$
\min_{\delta w} \frac{1}{2} \delta w^T \mathbf{H} \delta w \quad \\ \text{s.t.} \quad \mathbf{e}_q^T \delta w = -w_q
$$
构造函数：
$$
L = \frac{1}{2} \delta w^T \mathbf{H} \delta w - \lambda (\mathbf{e}_q^T \delta w + w_q)
$$
对 $\delta w$ 求导并令为 0：$e_q$ 是标准的 one-hot vector，第 $q$ 个位置为 1
$$
\mathbf{H} \delta w - \lambda \mathbf{e}_q = 0 \implies \delta w = \lambda \mathbf{H}^{-1} \mathbf{e}_q
$$
这意味最优权重更新 $\delta w$，与海森矩阵的逆矩阵 $\mathbf{H}^{-1}$ 的第 $q$ 列成正比。

利用约束条件 $\mathbf{e}_q^T \delta w = -w_q$ 求解 $\lambda$：
$$
\mathbf{e}_q^T (\lambda \mathbf{H}^{-1} \mathbf{e}_q) = -w_q
$$

$$
\lambda [\mathbf{H}^{-1}]_{qq} = -w_q \implies \lambda = \frac{-w_q}{[\mathbf{H}^{-1}]_{qq}}
$$

### 3. OBS 更新方向

**公式 A：最优更新方向（怎么改其他权重？）**

根据上述求解，可以得出 $\delta w$ 的值，它的含义是当你删除 $w_q$ 这个权重时，其他权重应该如何变化：
$$
\delta w = - \frac{w_q}{[\mathbf{H}^{-1}]_{qq}} \cdot \mathbf{H}^{-1}_{:,q}
$$
**公式 B：显著性得分（Saliency，删掉它的代价是多少？）**
将 $\delta w$ 代回 $\delta E$ 公式：
$$
L_q = \frac{1}{2} \frac{w_q^2}{[\mathbf{H}^{-1}]_{qq}}
$$
*含义：我们应该计算所有权重的 $L_q$，然后删除 $L_q$ 最小的那个权重，而不是删除绝对值最小的。*



## 3. 前置知识：OBQ 最优脑量化

**OBQ** 是 2022 年（GPTQ 的前身）提出的。它将 OBS 的思想从“剪枝”移植到了“量化”。

**核心区别**：

*   **OBS (剪枝)**：约束是 $\delta w_q = -w_q$（权重变 0）。
*   **OBQ (量化)**：约束是 $\delta w_q = \text{quant}(w_q) - w_q$（权重变最近的整数/量化值）。设这个量化误差为 $\Delta_q$。
*   OBQ 包括 GPTQ 的目标函数变为了 $$ E_l = || W_l X_l - \hat{W}_l X_l ||_2^2 $$（它们假设：**如果我能让每一层的输出，在量化前后尽可能保持不变，那么整个网络的最终输出也就保持不变。**）

#### 1. OBQ 的数学更新

直接套用 OBS 的推导（**因为在 OBS 中的推导没有定义函数形式，所以等价**），只需把约束值 $-w_q$ 换成 $\Delta_q$。

**OBQ 更新公式**：
$$
\delta w = \frac{\Delta_q}{[\mathbf{H}^{-1}]_{qq}} \cdot \mathbf{H}^{-1}_{:,q}
$$
这个公式告诉我们：**如果你把第 $q$ 个参数强行量化了（产生了误差 $\Delta_q$），你应该如何调整剩下的未量化参数来补偿这个误差。**

#### 2. OBQ 的算法流程（贪心策略）

OBQ 是一个逐个处理权重的过程。对于一个全连接层（权重矩阵 $W$）：

1.  **计算 Hessian**：$H = 2XX^T$。（加个 2 方便计算）

    推导：
    $$
    E = || \hat{W}X - WX ||_2^2 \\
    E = || (\hat{W} - W)X ||_2^2 \\
    E = || \Delta W X ||_2^2\\
    E = \Delta W (X X^T) \Delta W^T
    $$

2.  **计算逆矩阵**：$H^{-1}$。

3.  **循环迭代**（直到所有权重都被量化）：

    *   **寻找最优 victim**：遍历所有尚未量化的权重，计算如果量化它，会带来的误差代价（利用 OBS 的显著性公式变体）。
        $$ \text{Error}_i = \frac{(\text{quant}(w_i) - w_i)^2}{[H^{-1}]_{ii}} $$
    *   **选择**：找到 Error 最小的那个权重 $w_{best}$。
    *   **量化**：将 $w_{best}$ 量化，算出误差 $\Delta = q - w_{best}$。
    *   **补偿（核心步骤）**：利用 OBQ 更新公式，把 $\Delta$ 通过 $H^{-1}$ 的相关性，“抹平”到剩余所有未量化的权重上。
        *   注意：此时剩余权重的数值变了！这意味着原本可能量化误差很大的数，被补偿后可能变得容易量化了。
    *   **更新 Hessian**：因为 $w_{best}$ 已经固定了，它不再是变量，我们需要从 Hessian 矩阵中移除这一行一列（高斯消元）想具体了解可以参考：[GPTQ大模型量化算法原理详解（一） - 知乎](https://zhuanlan.zhihu.com/p/1929142220717537176)。

#### 3. OBQ 的问题

OBQ 的精度极高（因为它不仅补偿，还每次都贪心地找最好处理的权重先处理）。
但是它**太慢了**。

*   每次处理一个权重，都要更新整个权重矩阵。
*   每次都要在所有剩余权重里搜索下一个。
*   复杂度是 $O(d_{row} \cdot d_{col}^2)$。对于大模型（如 Llama 70B），这需要跑几百个小时，根本不可用。

![](picture/OBS.jpg)

---

## 4. 从 OBQ 到 GPTQ 的飞跃

理解了 OBQ，你就明白 GPTQ 做了什么神操作：

1.  **放弃贪心搜索，固定顺序**：
    OBQ 说：“我要每次挑误差最小的先量化”。
    GPTQ 说：“对于大模型，顺序其实不重要。我们就**按列顺序（1, 2, 3...）**量化，效果差不多。”(从上图可以看每行量化的权重是不同的顺序)
    > **补充**：虽然 GPTQ 放弃了贪心，但在实际工程中，如果能**根据对角线元素 $H_{ii}$ 降序排列**（先处理“硬骨头”），效果通常会更好。不过为了方便，直接按内存顺序处理也是主流做法。

    *   **推导**：这一步直接省去了每次 $O(d)$ 的搜索时间，并且让我们可以利用 Cholesky 分解预先算好 $H^{-1}$ 的信息，而不需要动态更新 $H^{-1}$。

    ![](picture/GPTQ.jpg)

2.  **Cholesky 分解：**

    首先明白为什么要进行分解：
    > **工程细节（阻尼 Damping）**：在实际计算中，海森矩阵 $H$ 可能是奇异的（不可逆）。为了数值稳定性，我们通常会在对角线上加一个微小的正数 $\lambda$（如平均对角线值的 1%），即 $H' = H + \lambda I$，确保它是正定的，这样才能进行 Cholesky 分解。

    从过程入手：

    量化补偿的计算如下：$$\delta w = \frac{\Delta_q}{[\mathbf{H}^{-1}]_{qq}} \cdot \mathbf{H}^{-1}_{:,q}$$

    需要 $H$ 矩阵的 $[q,q]$ 位置的值，以及 $H$ 矩阵的第 $q$ 列，那么在更新完后，第 $q$ 列就要删除了（否则后面的补偿使得前面的量化失败了），那么 $H$ 矩阵就要删除第 $q$ 行和第 $q$ 列。在 OBQ 中采取的方式是**高斯消元法**，有如下公式：（时间复杂度 ：$O(d^2)$ 如果有 $N$ 个参数则时间复杂度为 $O(Nd^2)$）
    $$
    H^{-1}_{new} = H^{-1}_{sub} - \frac{\mathbf{v}\mathbf{v}^T}{h_{11}}
    $$

    我们从递归的视角看一下 **Cholesky 分解**：$A = LL^T$ 目标就是给出一个矩阵将他分解为一个下三角矩阵。
    > **注意**：标准代码实现是对 $H$ 进行分解，但为了方便理解递归更新的原理，这里我们在数学推导上直接用 $H^{-1}$ 来演示，逻辑是等价的。

    为了方便理解，在推导过程直接用 $H^{-1}$ 来推导：
    $$
    H^{-1} = \begin{bmatrix} a_{11} & \mathbf{v}^T \\ \mathbf{v} & H^{-1}_{sub} \end{bmatrix} 
    $$
    *   $a_{11}$：左上角的元素。
    *   $\mathbf{v}$：第一列剩下的部分。
    *   $H^{-1}_{sub}$：右下角的子矩阵。

    同样，我们将目标矩阵 $L$ 也切分：
    $$
    L = \begin{bmatrix} l_{11} & 0 \\ \mathbf{l} & L_{next} \end{bmatrix}
    $$

    *   $l_{11}$：左上角元素。
    *   $\mathbf{l}$：第 1 列剩下的部分。
    *   $L_{next}$：右下角的子下三角矩阵（我们要递归求的部分）。

    建立等式：$A = L L^T$
    $$
    L L^T = \begin{bmatrix} l_{11} & 0 \\ \mathbf{l} & L_{next} \end{bmatrix} \times \begin{bmatrix} l_{11} & \mathbf{l}^T \\ 0 & L_{next}^T \end{bmatrix} = \begin{bmatrix} a_{11} & \mathbf{v}^T \\ \mathbf{v} & H^{-1}_{sub} \end{bmatrix}
    $$

    （1）$$ a_{11} = l_{11}^2 \implies l_{11} = \sqrt{a_{11}} $$

    （2）$$ \mathbf{v} = l_{11}\mathbf{l} \implies \mathbf{l} = \frac{1}{l_{11}}\mathbf{v} = \frac{\mathbf{v}}{\sqrt{a_{11}}} $$

    （3）$$ \mathbf{H^{-1}_{sub}} = \mathbf{l}\mathbf{l}^T + L_{next}L_{next}^T $$ **最关键的一步**

    我们要解出 $L_{next}$（为了继续递归），需要把 $\mathbf{l}\mathbf{l}^T$ 移项到左边：
    $$
    \underbrace{L_{next}L_{next}^T}_{\text{下一步的目标}} = \underbrace{\mathbf{H^{-1}_{sub}} - \mathbf{l}\mathbf{l}^T}_{\text{这就是 } \mathbf{H^{-1}_{new}}}
    $$
    然后带入 $\mathbf{l}$:
    $$
    \underbrace{H^{-1}_{new}}_{\text{更新后的逆矩阵}} 
    = \underbrace{H^{-1}_{sub}}_{\text{右下角子矩阵}} - \underbrace{\mathbf{l}\mathbf{l}^T}_{\text{Cholesky 减去的项}} 
    = \underbrace{H^{-1}_{sub} - \frac{\mathbf{v}\mathbf{v}^T}{h_{11}}}_{\text{OBQ/高斯消元 减去的项}}
    $$
    如此迭代下去，所有的 $H$ 就提前算好了。

3.  **Lazy Batch（懒惰批量）策略**

    它把矩阵切成一个个 **Block（比如 128 列一组）**。

    **步骤演示：**
    假设我们处理第 1 个 Block（第 1~128 列）：

    1.  **Block 内循环（在快速缓存中进行）：**
        > **形象理解**：这部分更新像一个**三角形**波浪。第 2 列依赖第 1 列的误差，第 3 列依赖前两列... 必须串行完成。
        *   量化第 1 列 $\to$ 算出误差。
        *   **只更新** Block 内部剩下的列（第 2~128 列）。**不碰** Block 外面的第 129~10000 列。
        *   量化第 2 列 $\to$ 算出误差。
        *   **只更新** Block 内部剩下的列（第 3~128 列）。
        *   ...
        *   直到第 128 列量化完。

    2.  **全局更新（GEMM 大招）：**
        *   现在，我们手里攒了 128 列的量化误差。
        *   我们一次性把这 128 列的误差，更新到后面所有的列（129~End）。
        *   这是一个 **矩阵 $\times$ 矩阵** 的乘法（GEMM）。
        *   **$W_{rest} \leftarrow W_{rest} - \text{Block\_Coeffs} \times \text{Block\_Errors}$**

    **为什么快？**
    *   **GEMV (矩阵-向量)** $\to$ **GEMM (矩阵-矩阵)**。
    *   GPU 对 GEMM 有极致优化（Tensor Core），数据读一次，可以进行很多次计算。
    *   **内存带宽利用率**从极低变成了极高。







### 总结对照表

| 特性         | OBS (1993)                  | OBQ (2022)             | GPTQ (2023)          |
| :----------- | :-------------------------- | :--------------------- | :------------------- |
| **目标**     | 剪枝 (Pruning)              | 量化 (Quantization)    | 量化 (Quantization)  |
| **操作**     | 权重设为 0                  | 权重设为 Int           | 权重设为 Int         |
| **策略**     | 全局寻找最不重要的权重      | 贪心寻找误差最小的权重 | **固定顺序 (按列)**  |
| **核心原理** | 二阶泰勒展开 + 拉格朗日乘子 | 同 OBS                 | 同 OBS               |
| **计算量**   | 极大                        | 大 (大模型跑不动)      | **极快 (分块优化)**  |
| **补偿机制** | 删除一个，调整其余          | 量化一个，调整其余     | 量化一列，调整后续列 |

